{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract patient ids from edf files\n",
    "from glob2 import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import mne \n",
    "import tqdm\n",
    "\n",
    "# read the list of paths of edf files\n",
    "glob_path_to_edf_files = \"..\\\\tuh_eeg_epilepsy\\\\edf\\\\*epilepsy\\\\*\\\\*\\\\*\\\\*\\\\*.edf\"\n",
    "edf_file_list = glob(glob_path_to_edf_files)\n",
    "\n",
    "# extract patient IDs from the file path, \n",
    "# create python set to extract unique elements from list,\n",
    "# convert to list again \n",
    "unique_epilepsy_patient_ids = list(set([x.split(\"\\\\\")[-1].split(\"_\")[0] for x in edf_file_list]))\n",
    "\n",
    "\n",
    "# create the index table and save it\n",
    "unique_epilepsy_patient_ids = [x.strip() for x in unique_epilepsy_patient_ids]\n",
    "\n",
    "# pick your desired preprocessing configuration.\n",
    "SAMPLING_FREQ = 250.0\n",
    "WINDOW_LENGTH_SECONDS = 60.0\n",
    "WINDOW_LENGTH_SAMPLES = int(WINDOW_LENGTH_SECONDS * SAMPLING_FREQ)\n",
    "\n",
    "# loop over one patient at a time, and add corresponding metadata to csv\n",
    "dataset_index_rows = [ ]\n",
    "label_count = { \n",
    "    \"epilepsy\": 0,\n",
    "    \"no_epilepsy\": 0\n",
    "}\n",
    "\n",
    "for idx, patient_id in tqdm(enumerate(unique_epilepsy_patient_ids)):\n",
    "  \n",
    "    # find all edf files corresponding to this patient id\n",
    "    patients_edf_file = f\"..\\\\tuh_eeg_epilepsy\\\\edf\\\\*epilepsy\\\\*\\\\*\\\\{patient_id}\\\\*\\\\{patient_id}_*.edf\"\n",
    "    patient_edf_file_list = glob(patients_edf_file)\n",
    "    assert len(patient_edf_file_list) >= 1\n",
    "        \n",
    "    # get label of the recording from the file name, ensure all labels \n",
    "    # for the same subject are the same\n",
    "    # the label of the recording is copied to each of its windows\n",
    "    labels = [x.split(\"\\\\\")[3] for x in patient_edf_file_list]\n",
    "    assert labels == [labels[0]]*len(labels)\n",
    "        \n",
    "    label = labels[0]\n",
    "    label_count[label] += 1\n",
    "    \n",
    "    # keep only the first file per patient\n",
    "    raw_file_path = patient_edf_file_list[0]\n",
    "    raw_data = mne.io.read_raw_edf(raw_file_path, verbose=False, preload=False)\n",
    "    \n",
    "    # generate window metadata = one row of dataset_index\n",
    "    window_iterator = range(0, int(int(raw_data.times[-1]) * SAMPLING_FREQ), WINDOW_LENGTH_SAMPLES) \n",
    "    for start_sample_index in window_iterator:\n",
    "\n",
    "        end_sample_index = start_sample_index + (WINDOW_LENGTH_SAMPLES - 1)\n",
    "        \n",
    "        # ensure 10 seconds are available in window and recording does not end\n",
    "        if end_sample_index > raw_data.n_times:\n",
    "            break\n",
    "\n",
    "        row = {}\n",
    "        row[\"patient_id\"] = patient_id\n",
    "        row[\"raw_file_path\"] = patient_edf_file_list[0]\n",
    "        row[\"record_length_seconds\"] = raw_data.times[-1]\n",
    "        # this is the desired SFREQ using which sample indices are derived.\n",
    "        # this is not the original SFREQ at which the data is recorded.\n",
    "        row[\"sampling_freq\"] = SAMPLING_FREQ\n",
    "        row[\"channel_config\"] = raw_file_path.split(\"\\\\\")[4]\n",
    "        row[\"start_sample_index\"] = start_sample_index\n",
    "        row[\"end_sample_index\"] = end_sample_index\n",
    "        row[\"text_label\"] = label\n",
    "        row[\"numeric_label\"] = 0 if label == \"no_epilepsy\" else 1\n",
    "        dataset_index_rows.append(row)\n",
    "        \n",
    "# create dataframe from rows and save it\n",
    "df = pd.DataFrame(dataset_index_rows, \n",
    "                    columns=[\"patient_id\", \n",
    "                             \"raw_file_path\",\n",
    "                             \"record_length_seconds\", \n",
    "                             \"sampling_freq\",\n",
    "                             \"channel_config\",\n",
    "                             \"start_sample_index\",\n",
    "                             \"end_sample_index\",\n",
    "                             \"text_label\",\n",
    "                             \"numeric_label\"])\n",
    "df.to_csv(f\"epilepsy_corpus_window_index_{str(int(WINDOW_LENGTH_SECONDS))}s.csv\",\n",
    "          index=False)\n",
    "\n",
    "# functions for preprocessing the eeg data\n",
    "def standardize_sensors(raw_data):\n",
    "    # the TUEP database has 3 EEG channel configurations: \n",
    "    # '02_tcp_le', '03_tcp_ar_a', '01_tcp_ar'\n",
    "\t# number of channels and channel names differ within these configurations\n",
    "\t# to be able to compare the different EEG readings we need to select channels\n",
    "\t# that are common for all configurations\n",
    "\n",
    "    # the list of 19 channels (their short labels) that we will use for analysing EEG data\n",
    "    channels_to_use = [\"FP1\", \"FP2\", \"F7\", \"F3\", \"FZ\", \"F4\", \"F8\",\n",
    "                          \"T3\", \"C3\", \"CZ\", \"C4\", \"T4\", \"T5\",\n",
    "                          \"P3\", \"PZ\", \"P4\", \"T6\", \"O1\", \"O2\"]\n",
    "    \n",
    "\t# the function to update channel names from original to new format:\n",
    "    ch_name_update_func = lambda ch: ch.split(' ')[-1].split('-')[0]\n",
    "    \n",
    "    # renaming the original channel names in one .edf file;\n",
    "    # the update will be written into the in-memory edf object\n",
    "    raw_data.rename_channels(mapping=ch_name_update_func)\n",
    "\n",
    "    raw_data = raw_data.pick_channels(channels_to_use, ordered=True)\n",
    "    \n",
    "     # check if all required channels are in the edf file\n",
    "    try:\n",
    "        assert all([ch in raw_data.info[\"ch_names\"] for ch in channels_to_use])\n",
    "    except:\n",
    "        print('Not all required channels are in the edf file.')\n",
    "\n",
    "    return raw_data\n",
    "\n",
    "def downsample(raw_data, freq=250):\n",
    "    raw_data = raw_data.resample(sfreq=freq, n_jobs=-2, verbose=False)\n",
    "    return raw_data, freq\n",
    "\n",
    "\n",
    "# compute mi and correlation matrices\n",
    "index_df = pd.read_csv(\"epilepsy_corpus_window_index_60s.csv\")\n",
    "reduced_index_df = pd.DataFrame()\n",
    "\n",
    "# we will use only up to 10 EEG windows per patient\n",
    "n_windows_per_patient = 10\n",
    "\n",
    "for p in index_df.patient_id.unique().tolist():\n",
    "    reduced_index_df = pd.concat([reduced_index_df, \n",
    "                          index_df.query(f'patient_id == {p}').iloc[:n_windows_per_patient,:]])\n",
    "\n",
    "reduced_index_df = reduced_index_df.reset_index()\n",
    "reduced_index_df.to_csv('reduced_epilepsy_corpus_window_index_60s.csv', index=False)\n",
    "grouped_df = reduced_index_df.groupby(\"raw_file_path\")\n",
    "\n",
    "num_channels = 19\n",
    "\n",
    "mutual_info_matrix = np.zeros((reduced_index_df.shape[0], num_channels**2))\n",
    "correlation_matrix = np.zeros((reduced_index_df.shape[0], num_channels**2))\n",
    "all_window_data = []\n",
    "\n",
    "# open up one raw_file at a time.\n",
    "for raw_file_path, group_df in tqdm(grouped_df):    \n",
    "    windows_list = group_df.index.tolist()\n",
    "\n",
    "    raw_data = mne.io.read_raw_edf(raw_file_path, preload=True, verbose=False)\n",
    "    raw_data = standardize_sensors(raw_data)\n",
    "    raw_data, sfreq = downsample(raw_data, SAMPLING_FREQ)\n",
    "    \n",
    "    # data is ready for feature extraction, loop over windows, extract features\n",
    "    for window_idx in windows_list:\n",
    "     \n",
    "        # get raw data for the window\n",
    "        start_sample = group_df.loc[window_idx]['start_sample_index']\n",
    "        stop_sample = group_df.loc[window_idx]['end_sample_index']\n",
    "        window_data = raw_data.get_data(start=start_sample, stop=stop_sample)\n",
    "        all_window_data.append(window_data)\n",
    "        \n",
    "        df = pd.DataFrame(window_data.T)\n",
    "        corr_matrix = df.corr().values \n",
    "        corr_matrix_values = corr_matrix.reshape(1, num_channels**2)\n",
    "        correlation_matrix[window_idx] = corr_matrix_values\n",
    "        \n",
    "        mi_matrix = compute_mi_matrix(df) \n",
    "        normed_mi_matrix = compute_normed_mi_matrix(mi_matrix)\n",
    "        normed_mi_matrix_values = normed_mi_matrix.reshape(1, num_channels**2)   \n",
    "        mutual_info_matrix[window_idx] = normed_mi_matrix_values\n",
    "                \n",
    "# save the features and labels as numpy array to disk\n",
    "np.save(\"reduced_X_windows_epilepsy_corpus_60s.npy\", np.array(all_window_data))\n",
    "np.save(\"reduced_X_normed_mi_epilepsy_corpus_60s.npy\", mutual_info_matrix)\n",
    "np.save(\"reduced_X_correlation_epilepsy_corpus_60s.npy\", correlation_matrix)\n",
    "np.save(\"reduced_y_epilepsy_corpus_60s.npy\", reduced_index_df[\"text_label\"].to_numpy())\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
